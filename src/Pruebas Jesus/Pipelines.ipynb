{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.experimental import enable_iterative_imputer  # Necesario para habilitar IterativeImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Leer el CSV\n",
    "data = pd.read_csv('../../data/EstudioCrediticio_TrainP.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de datos y borrado columnas id y creditoaprobado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la primera columna\n",
    "data = data.iloc[:, 1:]\n",
    "\n",
    "# Eliminar la penúltima columna\n",
    "data = data.iloc[:, :-2].join(data.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtener variables predictoras y dependiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar las características (X) y la variable a predecir (y)\n",
    "X = data.iloc[:, :-1]  # Todas las columnas menos la última\n",
    "y = data.iloc[:, -1]   # La última columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline con simple imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas numéricas y categóricas\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Pipeline para variables categóricas (Imputación + OneHotEncoder)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputar con el valor más frecuente\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Pipeline para variables numéricas (Imputación + Escalado)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Imputar con la media\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# Combinación de transformaciones para columnas categóricas y numéricas\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Crear pipeline final con preprocesamiento y modelo\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline con iterative imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas numéricas y categóricas\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Pipeline para variables categóricas (Imputación + OneHotEncoder)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputar con el valor más frecuente\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Pipeline para variables numéricas (IterativeImputer + Escalado)\n",
    "numeric_transformer_iterative = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer()),  # Imputación iterativa\n",
    "    ('scaler', RobustScaler())\n",
    "])\n",
    "\n",
    "# Combinación de transformaciones para columnas categóricas y numéricas\n",
    "preprocessor_iterative = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_iterative, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Crear pipeline final con preprocesamiento y modelo\n",
    "model_iterative = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_iterative),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "# Identificar columnas numéricas y categóricas\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "print(len(numeric_cols))\n",
    "\n",
    "# Pipeline para variables categóricas (Imputación + OneHotEncoder)\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Imputar con el valor más frecuente\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Pipeline para variables numéricas (Imputación + Escalado + PCA)\n",
    "numeric_transformer_pca = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Imputación con la media\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('pca', PCA(n_components=16))  # Aplicar PCA con 5 componentes principales\n",
    "])\n",
    "\n",
    "# Combinación de transformaciones para columnas categóricas y numéricas\n",
    "preprocessor_pca = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer_pca, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Crear pipeline final con preprocesamiento y modelo\n",
    "model_pca = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_pca),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'SimpleImputer': model, 'IterativeImputer': model_iterative, 'PCA': model_pca}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.values():\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: SimpleImputer\n",
      "MAE del conjunto de entrenamiento: 1.15\n",
      "MAE del conjunto de prueba: 8.34\n",
      "Modelo: IterativeImputer\n",
      "MAE del conjunto de entrenamiento: 1.14\n",
      "MAE del conjunto de prueba: 8.20\n",
      "Modelo: PCA\n",
      "MAE del conjunto de entrenamiento: 3.88\n",
      "MAE del conjunto de prueba: 27.93\n"
     ]
    }
   ],
   "source": [
    "for model in models.keys():\n",
    "    print(f\"Modelo: {model}\")\n",
    "    # Evaluar el modelo\n",
    "    mae_train = mean_squared_error(y_train, models.get(model).predict(X_train))\n",
    "    mae_test = mean_squared_error(y_test, models.get(model).predict(X_test))\n",
    "\n",
    "    print(f\"MAE del conjunto de entrenamiento: {mae_train:.2f}\")\n",
    "    print(f\"MAE del conjunto de prueba: {mae_test:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
